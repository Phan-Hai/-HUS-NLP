{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85346983",
   "metadata": {},
   "source": [
    "# Lab 5: Phân loại Văn bản với RNN/LSTM\n",
    "Thực hiện đầy đủ 5 nhiệm vụ và so sánh các phương pháp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a525aa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from gensim.models import Word2Vec\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e21324",
   "metadata": {},
   "source": [
    "# BƯỚC 0: THIẾT LẬP MÔI TRƯỜNG VÀ TẢI DỮ LIỆU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8efc9787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (8954, 2)\n",
      "Validation shape: (1076, 2)\n",
      "Test shape: (1076, 2)\n",
      "\n",
      "Số lớp intent: 64\n",
      "\n",
      "Ví dụ dữ liệu:\n",
      "                                                text       intent\n",
      "0                what alarms do i have set right now  alarm_query\n",
      "1                    checkout today alarm of meeting  alarm_query\n",
      "2                              report alarm settings  alarm_query\n",
      "3  see see for me the alarms that you have set to...  alarm_query\n",
      "4                       is there an alarm for ten am  alarm_query\n",
      "\n",
      "Số lớp sau encoding: 64\n"
     ]
    }
   ],
   "source": [
    "# Đọc dữ liệu\n",
    "df_train = pd.read_csv(r'D:\\10. ky1nam4\\NLP\\data\\hwu\\train.csv', sep=',', header=None, names=['text', 'intent'], skiprows=1)\n",
    "df_val = pd.read_csv(r'D:\\10. ky1nam4\\NLP\\data\\hwu\\val.csv', sep=',', header=None, names=['text', 'intent'], skiprows=1)\n",
    "df_test = pd.read_csv(r'D:\\10. ky1nam4\\NLP\\data\\hwu\\test.csv', sep=',', header=None, names=['text', 'intent'], skiprows=1)\n",
    "\n",
    "print(f\"Train shape: {df_train.shape}\")\n",
    "print(f\"Validation shape: {df_val.shape}\")\n",
    "print(f\"Test shape: {df_test.shape}\")\n",
    "print(f\"\\nSố lớp intent: {df_train['intent'].nunique()}\")\n",
    "print(\"\\nVí dụ dữ liệu:\")\n",
    "print(df_train.head())\n",
    "\n",
    "# Mã hóa nhãn\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(pd.concat([df_train['intent'], df_val['intent'], df_test['intent']]))\n",
    "\n",
    "y_train = label_encoder.transform(df_train['intent'])\n",
    "y_val = label_encoder.transform(df_val['intent'])\n",
    "y_test = label_encoder.transform(df_test['intent'])\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(f\"\\nSố lớp sau encoding: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bed1289",
   "metadata": {},
   "source": [
    "# NHIỆM VỤ 1: TF-IDF + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f70f221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang huấn luyện mô hình TF-IDF + LR...\n",
      "\n",
      "F1-score (Macro) trên tập test: 0.8289\n",
      "\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alarm_query       0.95      0.95      0.95        19\n",
      "            alarm_remove       1.00      0.73      0.84        11\n",
      "               alarm_set       0.85      0.89      0.87        19\n",
      "       audio_volume_down       1.00      0.75      0.86         8\n",
      "       audio_volume_mute       0.92      0.80      0.86        15\n",
      "         audio_volume_up       1.00      1.00      1.00        13\n",
      "          calendar_query       0.55      0.58      0.56        19\n",
      "         calendar_remove       0.78      0.95      0.86        19\n",
      "            calendar_set       0.87      0.68      0.76        19\n",
      "          cooking_recipe       0.92      0.63      0.75        19\n",
      "        datetime_convert       0.78      0.88      0.82         8\n",
      "          datetime_query       0.71      0.89      0.79        19\n",
      "        email_addcontact       0.88      0.88      0.88         8\n",
      "             email_query       0.83      0.79      0.81        19\n",
      "      email_querycontact       0.93      0.68      0.79        19\n",
      "         email_sendemail       0.77      0.89      0.83        19\n",
      "          general_affirm       0.95      1.00      0.97        19\n",
      "     general_commandstop       1.00      1.00      1.00        19\n",
      "         general_confirm       1.00      1.00      1.00        19\n",
      "        general_dontcare       0.90      1.00      0.95        19\n",
      "         general_explain       1.00      1.00      1.00        19\n",
      "            general_joke       1.00      1.00      1.00        12\n",
      "          general_negate       1.00      0.95      0.97        19\n",
      "          general_praise       0.95      1.00      0.97        19\n",
      "          general_quirky       0.31      0.26      0.29        19\n",
      "          general_repeat       0.95      1.00      0.97        19\n",
      "            iot_cleaning       1.00      1.00      1.00        16\n",
      "              iot_coffee       0.90      0.95      0.92        19\n",
      "     iot_hue_lightchange       0.79      0.79      0.79        19\n",
      "        iot_hue_lightdim       0.83      0.83      0.83        12\n",
      "        iot_hue_lightoff       0.86      0.95      0.90        19\n",
      "         iot_hue_lighton       0.40      0.67      0.50         3\n",
      "         iot_hue_lightup       0.93      0.93      0.93        14\n",
      "            iot_wemo_off       0.80      0.89      0.84         9\n",
      "             iot_wemo_on       0.62      0.71      0.67         7\n",
      "       lists_createoradd       0.65      0.79      0.71        19\n",
      "             lists_query       0.79      0.79      0.79        19\n",
      "            lists_remove       0.86      0.95      0.90        19\n",
      "          music_likeness       0.57      0.67      0.62        18\n",
      "             music_query       0.73      0.58      0.65        19\n",
      "          music_settings       1.00      0.43      0.60         7\n",
      "              news_query       0.85      0.58      0.69        19\n",
      "          play_audiobook       0.90      0.95      0.92        19\n",
      "               play_game       0.85      0.58      0.69        19\n",
      "              play_music       0.52      0.63      0.57        19\n",
      "           play_podcasts       1.00      0.84      0.91        19\n",
      "              play_radio       0.94      0.79      0.86        19\n",
      "             qa_currency       0.89      0.89      0.89        19\n",
      "           qa_definition       0.95      0.95      0.95        19\n",
      "              qa_factoid       0.43      0.63      0.51        19\n",
      "                qa_maths       0.93      0.93      0.93        14\n",
      "                qa_stock       0.95      0.95      0.95        19\n",
      "   recommendation_events       0.75      0.79      0.77        19\n",
      "recommendation_locations       0.80      0.84      0.82        19\n",
      "   recommendation_movies       0.91      1.00      0.95        10\n",
      "             social_post       0.95      0.95      0.95        19\n",
      "            social_query       0.79      0.83      0.81        18\n",
      "          takeaway_order       0.76      0.68      0.72        19\n",
      "          takeaway_query       0.89      0.89      0.89        19\n",
      "         transport_query       0.70      0.84      0.76        19\n",
      "          transport_taxi       1.00      1.00      1.00        18\n",
      "        transport_ticket       0.94      0.79      0.86        19\n",
      "       transport_traffic       0.95      0.95      0.95        19\n",
      "           weather_query       0.68      0.68      0.68        19\n",
      "\n",
      "                accuracy                           0.83      1076\n",
      "               macro avg       0.84      0.83      0.83      1076\n",
      "            weighted avg       0.84      0.83      0.83      1076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tạo pipeline\n",
    "tfidf_lr_pipeline = make_pipeline(\n",
    "    TfidfVectorizer(max_features=5000, ngram_range=(1, 2)),\n",
    "    LogisticRegression(max_iter=1000, random_state=42)\n",
    ")\n",
    "\n",
    "# Huấn luyện\n",
    "print(\"Đang huấn luyện mô hình TF-IDF + LR...\")\n",
    "tfidf_lr_pipeline.fit(df_train['text'], y_train)\n",
    "\n",
    "# Dự đoán và đánh giá\n",
    "y_pred_tfidf = tfidf_lr_pipeline.predict(df_test['text'])\n",
    "f1_tfidf = f1_score(y_test, y_pred_tfidf, average='macro')\n",
    "\n",
    "print(f\"\\nF1-score (Macro) trên tập test: {f1_tfidf:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_tfidf, \n",
    "                          target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f954c35d",
   "metadata": {},
   "source": [
    "# NHIỆM VỤ 2: Word2Vec (Trung bình) + Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31feb254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang huấn luyện Word2Vec...\n",
      "Đang chuyển đổi câu thành vector...\n",
      "\n",
      "Kiến trúc mô hình Word2Vec + Dense:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m12,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,344</span> (99.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,344\u001b[0m (99.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,344</span> (99.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,344\u001b[0m (99.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Đang huấn luyện...\n",
      "Epoch 1/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0378 - loss: 4.0397 - val_accuracy: 0.1403 - val_loss: 3.2974\n",
      "Epoch 2/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1223 - loss: 3.3580 - val_accuracy: 0.2165 - val_loss: 2.9505\n",
      "Epoch 3/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1580 - loss: 3.1015 - val_accuracy: 0.2519 - val_loss: 2.7633\n",
      "Epoch 4/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1902 - loss: 2.9399 - val_accuracy: 0.2797 - val_loss: 2.6201\n",
      "Epoch 5/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2144 - loss: 2.8108 - val_accuracy: 0.3243 - val_loss: 2.4961\n",
      "Epoch 6/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2471 - loss: 2.6928 - val_accuracy: 0.3401 - val_loss: 2.4044\n",
      "Epoch 7/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2702 - loss: 2.5903 - val_accuracy: 0.3652 - val_loss: 2.3451\n",
      "Epoch 8/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2829 - loss: 2.5546 - val_accuracy: 0.3699 - val_loss: 2.3006\n",
      "Epoch 9/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3009 - loss: 2.5113 - val_accuracy: 0.3550 - val_loss: 2.2682\n",
      "Epoch 10/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3028 - loss: 2.4599 - val_accuracy: 0.3903 - val_loss: 2.2025\n",
      "Epoch 11/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3152 - loss: 2.4160 - val_accuracy: 0.3848 - val_loss: 2.1798\n",
      "Epoch 12/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3239 - loss: 2.3783 - val_accuracy: 0.4061 - val_loss: 2.1443\n",
      "Epoch 13/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3328 - loss: 2.3440 - val_accuracy: 0.4043 - val_loss: 2.1140\n",
      "Epoch 14/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3349 - loss: 2.3259 - val_accuracy: 0.4080 - val_loss: 2.1026\n",
      "Epoch 15/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3372 - loss: 2.3177 - val_accuracy: 0.4275 - val_loss: 2.0830\n",
      "Epoch 16/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3497 - loss: 2.2785 - val_accuracy: 0.4182 - val_loss: 2.0648\n",
      "Epoch 17/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3606 - loss: 2.2461 - val_accuracy: 0.4294 - val_loss: 2.0532\n",
      "Epoch 18/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3622 - loss: 2.2375 - val_accuracy: 0.4387 - val_loss: 2.0249\n",
      "Epoch 19/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3512 - loss: 2.2241 - val_accuracy: 0.4266 - val_loss: 2.0057\n",
      "Epoch 20/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3726 - loss: 2.1909 - val_accuracy: 0.4387 - val_loss: 1.9899\n",
      "Epoch 21/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3874 - loss: 2.1703 - val_accuracy: 0.4526 - val_loss: 1.9624\n",
      "Epoch 22/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3752 - loss: 2.1943 - val_accuracy: 0.4461 - val_loss: 1.9399\n",
      "Epoch 23/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3822 - loss: 2.1459 - val_accuracy: 0.4368 - val_loss: 1.9602\n",
      "Epoch 24/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3789 - loss: 2.1800 - val_accuracy: 0.4535 - val_loss: 1.9172\n",
      "Epoch 25/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3829 - loss: 2.1387 - val_accuracy: 0.4545 - val_loss: 1.9229\n",
      "Epoch 26/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3899 - loss: 2.1065 - val_accuracy: 0.4545 - val_loss: 1.9192\n",
      "Epoch 27/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3862 - loss: 2.1022 - val_accuracy: 0.4638 - val_loss: 1.8991\n",
      "Epoch 28/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3848 - loss: 2.1180 - val_accuracy: 0.4721 - val_loss: 1.8999\n",
      "Epoch 29/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4018 - loss: 2.0859 - val_accuracy: 0.4610 - val_loss: 1.8694\n",
      "Epoch 30/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4028 - loss: 2.1049 - val_accuracy: 0.4693 - val_loss: 1.8599\n",
      "\n",
      "Test Loss: 1.9352\n",
      "Test Accuracy: 0.4563\n",
      "F1-score (Macro): 0.4088\n"
     ]
    }
   ],
   "source": [
    "sentences_train = [text.lower().split() for text in df_train['text']]\n",
    "sentences_val = [text.lower().split() for text in df_val['text']]\n",
    "sentences_test = [text.lower().split() for text in df_test['text']]\n",
    "\n",
    "print(\"Đang huấn luyện Word2Vec...\")\n",
    "w2v_model = Word2Vec(sentences=sentences_train, \n",
    "                     vector_size=100, \n",
    "                     window=5, \n",
    "                     min_count=1, \n",
    "                     workers=4,\n",
    "                     epochs=10,\n",
    "                     seed=42)\n",
    "\n",
    "def sentence_to_avg_vector(tokens, model):\n",
    "    vectors = []\n",
    "    for word in tokens:\n",
    "        if word in model.wv:\n",
    "            vectors.append(model.wv[word])\n",
    "    \n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    \n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "print(\"Đang chuyển đổi câu thành vector...\")\n",
    "X_train_avg = np.array([sentence_to_avg_vector(sent, w2v_model) \n",
    "                        for sent in sentences_train])\n",
    "X_val_avg = np.array([sentence_to_avg_vector(sent, w2v_model) \n",
    "                      for sent in sentences_val])\n",
    "X_test_avg = np.array([sentence_to_avg_vector(sent, w2v_model) \n",
    "                       for sent in sentences_test])\n",
    "\n",
    "w2v_model_nn = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(w2v_model.vector_size,)),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "w2v_model_nn.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"\\nKiến trúc mô hình Word2Vec + Dense:\")\n",
    "w2v_model_nn.summary()\n",
    "\n",
    "print(\"\\nĐang huấn luyện...\")\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history_w2v = w2v_model_nn.fit(\n",
    "    X_train_avg, y_train,\n",
    "    validation_data=(X_val_avg, y_val),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "test_loss_w2v, test_acc_w2v = w2v_model_nn.evaluate(X_test_avg, y_test, verbose=0)\n",
    "y_pred_w2v = np.argmax(w2v_model_nn.predict(X_test_avg, verbose=0), axis=1)\n",
    "f1_w2v = f1_score(y_test, y_pred_w2v, average='macro')\n",
    "\n",
    "print(f\"\\nTest Loss: {test_loss_w2v:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc_w2v:.4f}\")\n",
    "print(f\"F1-score (Macro): {f1_w2v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e06ec2",
   "metadata": {},
   "source": [
    "# NHIỆM VỤ 3: Embedding Pre-trained + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c69e6c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape sau padding: (8954, 50)\n",
      "Embedding matrix shape: (4265, 100)\n",
      "Từ tìm thấy trong Word2Vec: 4197/4265\n",
      "\n",
      "Kiến trúc mô hình LSTM Pre-trained:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">426,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │       \u001b[38;5;34m426,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">426,500</span> (1.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m426,500\u001b[0m (1.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">426,500</span> (1.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m426,500\u001b[0m (1.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Đang huấn luyện...\n",
      "Epoch 1/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.0165 - loss: 4.1493 - val_accuracy: 0.0177 - val_loss: 4.1306\n",
      "Epoch 2/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.0175 - loss: 4.1405 - val_accuracy: 0.0177 - val_loss: 4.1258\n",
      "Epoch 3/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.0165 - loss: 4.1336 - val_accuracy: 0.0177 - val_loss: 4.1256\n",
      "Epoch 4/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.0186 - loss: 4.1356 - val_accuracy: 0.0177 - val_loss: 4.1258\n",
      "Epoch 5/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.0188 - loss: 4.1330 - val_accuracy: 0.0177 - val_loss: 4.1248\n",
      "Epoch 6/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.0176 - loss: 4.1341 - val_accuracy: 0.0177 - val_loss: 4.1242\n",
      "Epoch 7/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.0159 - loss: 4.1318 - val_accuracy: 0.0177 - val_loss: 4.1243\n",
      "Epoch 8/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.0223 - loss: 4.1324 - val_accuracy: 0.0177 - val_loss: 4.1248\n",
      "Epoch 9/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.0155 - loss: 4.1317 - val_accuracy: 0.0177 - val_loss: 4.1247\n",
      "Epoch 10/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.0154 - loss: 4.1316 - val_accuracy: 0.0177 - val_loss: 4.1247\n",
      "Epoch 11/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.0187 - loss: 4.1296 - val_accuracy: 0.0177 - val_loss: 4.1242\n",
      "\n",
      "Test Loss: 4.1242\n",
      "Test Accuracy: 0.0177\n",
      "F1-score (Macro): 0.0005\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 5000\n",
    "max_len = 50\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<UNK>\")\n",
    "tokenizer.fit_on_texts(df_train['text'])\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(df_train['text'])\n",
    "val_sequences = tokenizer.texts_to_sequences(df_val['text'])\n",
    "test_sequences = tokenizer.texts_to_sequences(df_test['text'])\n",
    "\n",
    "X_train_pad = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n",
    "X_val_pad = pad_sequences(val_sequences, maxlen=max_len, padding='post')\n",
    "X_test_pad = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "print(f\"Shape sau padding: {X_train_pad.shape}\")\n",
    "\n",
    "# actual_vocab_size = min(vocab_size, len(tokenizer.word_index) + 1)\n",
    "actual_vocab_size = max([np.max(X_train_pad), np.max(X_val_pad), np.max(X_test_pad)]) + 1\n",
    "embedding_dim = w2v_model.vector_size\n",
    "\n",
    "embedding_matrix = np.zeros((actual_vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < actual_vocab_size and word in w2v_model.wv:\n",
    "        embedding_matrix[i] = w2v_model.wv[word]\n",
    "\n",
    "print(f\"Embedding matrix shape: {embedding_matrix.shape}\")\n",
    "words_found = np.sum(np.any(embedding_matrix != 0, axis=1))\n",
    "print(f\"Từ tìm thấy trong Word2Vec: {words_found}/{actual_vocab_size}\")\n",
    "\n",
    "lstm_model_pretrained = Sequential([\n",
    "    Embedding(\n",
    "        input_dim=actual_vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=max_len,\n",
    "        trainable=True\n",
    "    ),\n",
    "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "lstm_model_pretrained.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"\\nKiến trúc mô hình LSTM Pre-trained:\")\n",
    "lstm_model_pretrained.summary()\n",
    "\n",
    "# Huấn luyện\n",
    "print(\"\\nĐang huấn luyện...\")\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history_lstm_pre = lstm_model_pretrained.fit(\n",
    "    X_train_pad, y_train,\n",
    "    validation_data=(X_val_pad, y_val),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Đánh giá\n",
    "test_loss_lstm_pre, test_acc_lstm_pre = lstm_model_pretrained.evaluate(\n",
    "    X_test_pad, y_test, verbose=0)\n",
    "y_pred_lstm_pre = np.argmax(lstm_model_pretrained.predict(X_test_pad, verbose=0), axis=1)\n",
    "f1_lstm_pre = f1_score(y_test, y_pred_lstm_pre, average='macro')\n",
    "\n",
    "print(f\"\\nTest Loss: {test_loss_lstm_pre:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc_lstm_pre:.4f}\")\n",
    "print(f\"F1-score (Macro): {f1_lstm_pre:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c7238a",
   "metadata": {},
   "source": [
    "# NHIỆM VỤ 4: Embedding học từ đầu + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "634960ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kiến trúc mô hình LSTM từ đầu:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Đang huấn luyện...\n",
      "Epoch 1/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.0152 - loss: 4.1534 - val_accuracy: 0.0177 - val_loss: 4.1348\n",
      "Epoch 2/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.0142 - loss: 4.1389 - val_accuracy: 0.0177 - val_loss: 4.1282\n",
      "Epoch 3/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.0165 - loss: 4.1389 - val_accuracy: 0.0177 - val_loss: 4.1263\n",
      "Epoch 4/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.0201 - loss: 4.1344 - val_accuracy: 0.0177 - val_loss: 4.1270\n",
      "Epoch 5/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.0159 - loss: 4.1346 - val_accuracy: 0.0177 - val_loss: 4.1253\n",
      "Epoch 6/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.0157 - loss: 4.1340 - val_accuracy: 0.0177 - val_loss: 4.1247\n",
      "Epoch 7/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.0171 - loss: 4.1319 - val_accuracy: 0.0177 - val_loss: 4.1243\n",
      "Epoch 8/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.0183 - loss: 4.1317 - val_accuracy: 0.0177 - val_loss: 4.1248\n",
      "Epoch 9/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.0163 - loss: 4.1318 - val_accuracy: 0.0177 - val_loss: 4.1239\n",
      "Epoch 10/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.0192 - loss: 4.1323 - val_accuracy: 0.0177 - val_loss: 4.1257\n",
      "Epoch 11/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.0162 - loss: 4.1313 - val_accuracy: 0.0177 - val_loss: 4.1242\n",
      "Epoch 12/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.0166 - loss: 4.1305 - val_accuracy: 0.0177 - val_loss: 4.1247\n",
      "Epoch 13/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.0156 - loss: 4.1313 - val_accuracy: 0.0177 - val_loss: 4.1241\n",
      "Epoch 14/30\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.0147 - loss: 4.1320 - val_accuracy: 0.0177 - val_loss: 4.1242\n",
      "\n",
      "Test Loss: 4.1239\n",
      "Test Accuracy: 0.0177\n",
      "F1-score (Macro): 0.0005\n"
     ]
    }
   ],
   "source": [
    "lstm_model_scratch = Sequential([\n",
    "    Embedding(\n",
    "        input_dim=actual_vocab_size,\n",
    "        output_dim=100,\n",
    "        input_length=max_len\n",
    "        # trainable=True (mặc định)\n",
    "    ),\n",
    "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "lstm_model_scratch.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Kiến trúc mô hình LSTM từ đầu:\")\n",
    "lstm_model_scratch.summary()\n",
    "\n",
    "# Huấn luyện\n",
    "print(\"\\nĐang huấn luyện...\")\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history_lstm_scratch = lstm_model_scratch.fit(\n",
    "    X_train_pad, y_train,\n",
    "    validation_data=(X_val_pad, y_val),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Đánh giá\n",
    "test_loss_lstm_scratch, test_acc_lstm_scratch = lstm_model_scratch.evaluate(\n",
    "    X_test_pad, y_test, verbose=0)\n",
    "y_pred_lstm_scratch = np.argmax(lstm_model_scratch.predict(X_test_pad, verbose=0), axis=1)\n",
    "f1_lstm_scratch = f1_score(y_test, y_pred_lstm_scratch, average='macro')\n",
    "\n",
    "print(f\"\\nTest Loss: {test_loss_lstm_scratch:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc_lstm_scratch:.4f}\")\n",
    "print(f\"F1-score (Macro): {f1_lstm_scratch:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d09acab",
   "metadata": {},
   "source": [
    "# PHÂN TÍCH ĐỊNH TÍNH - Kiểm tra trên các câu khó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c86308b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kiểm tra dự đoán trên các câu khó:\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Câu 1: 'can you remind me to not call my mom'\n",
      "======================================================================\n",
      "TF-IDF + LR: calendar_set\n",
      "Word2Vec + Dense: social_post\n",
      "LSTM (Pre-trained): general_dontcare\n",
      "LSTM (Scratch): play_audiobook\n",
      "\n",
      "======================================================================\n",
      "Câu 2: 'is it going to be sunny or rainy tomorrow'\n",
      "======================================================================\n",
      "TF-IDF + LR: weather_query\n",
      "Word2Vec + Dense: weather_query\n",
      "LSTM (Pre-trained): general_dontcare\n",
      "LSTM (Scratch): play_audiobook\n",
      "\n",
      "======================================================================\n",
      "Câu 3: 'find a flight from new york to london but not through paris'\n",
      "======================================================================\n",
      "TF-IDF + LR: transport_query\n",
      "Word2Vec + Dense: email_sendemail\n",
      "LSTM (Pre-trained): general_dontcare\n",
      "LSTM (Scratch): play_audiobook\n"
     ]
    }
   ],
   "source": [
    "test_samples = [\n",
    "    \"can you remind me to not call my mom\",\n",
    "    \"is it going to be sunny or rainy tomorrow\",\n",
    "    \"find a flight from new york to london but not through paris\"\n",
    "]\n",
    "\n",
    "print(\"\\nKiểm tra dự đoán trên các câu khó:\\n\")\n",
    "\n",
    "for i, sample in enumerate(test_samples, 1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Câu {i}: '{sample}'\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Chuẩn bị input cho từng mô hình\n",
    "    # TF-IDF\n",
    "    pred_tfidf = tfidf_lr_pipeline.predict([sample])[0]\n",
    "    \n",
    "    # Word2Vec\n",
    "    tokens = sample.lower().split()\n",
    "    vec = sentence_to_avg_vector(tokens, w2v_model).reshape(1, -1)\n",
    "    pred_w2v = np.argmax(w2v_model_nn.predict(vec, verbose=0))\n",
    "    \n",
    "    # LSTM models\n",
    "    seq = tokenizer.texts_to_sequences([sample])\n",
    "    seq_pad = pad_sequences(seq, maxlen=max_len, padding='post')\n",
    "    pred_lstm_pre = np.argmax(lstm_model_pretrained.predict(seq_pad, verbose=0))\n",
    "    pred_lstm_scratch = np.argmax(lstm_model_scratch.predict(seq_pad, verbose=0))\n",
    "    \n",
    "    print(f\"TF-IDF + LR: {label_encoder.classes_[pred_tfidf]}\")\n",
    "    print(f\"Word2Vec + Dense: {label_encoder.classes_[pred_w2v]}\")\n",
    "    print(f\"LSTM (Pre-trained): {label_encoder.classes_[pred_lstm_pre]}\")\n",
    "    print(f\"LSTM (Scratch): {label_encoder.classes_[pred_lstm_scratch]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75030a70",
   "metadata": {},
   "source": [
    "# Báo Cáo Lab 5: Phân loại Văn bản với RNN/LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0133d40",
   "metadata": {},
   "source": [
    "# Báo Cáo Lab 5: Phân loại Văn bản với RNN/LSTM\n",
    "\n",
    "## 1. Tổng Quan Kết Quả Định Lượng\n",
    "\n",
    "| Pipeline | F1-score (Macro) | Test Loss | Test Accuracy |\n",
    "|----------|------------------|-----------|---------------|\n",
    "| TF-IDF + Logistic Regression | **0.83** | N/A | **0.83** |\n",
    "| Word2Vec (Avg) + Dense | 0.41 | 1.94 | 0.46 |\n",
    "| Embedding (Pre-trained) + LSTM | 0.0005 | 4.12 | 0.02 |\n",
    "| Embedding (Scratch) + LSTM | 0.0005 | 4.12 | 0.02 |\n",
    "\n",
    "### Nhận Xét Chung về Kết Quả\n",
    "\n",
    "Kết quả thí nghiệm cho thấy một bức tranh **ngược lại hoàn toàn** với kỳ vọng lý thuyết:\n",
    "- **TF-IDF + LR đạt hiệu suất tốt nhất** (F1: 0.83)\n",
    "- **Các mô hình LSTM hoàn toàn thất bại** (F1 ≈ 0, chỉ dự đoán 1-2 lớp)\n",
    "- Word2Vec + Dense đạt kết quả trung bình (F1: 0.41)\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Phân Tích Định Tính - Dự Đoán trên Câu Khó\n",
    "\n",
    "### **Câu 1: \"can you remind me to NOT call my mom\"**\n",
    "**Nhãn thực tế mong đợi:** `reminder_create`\n",
    "\n",
    "| Mô hình | Dự đoán | Đánh giá |\n",
    "|---------|---------|----------|\n",
    "| TF-IDF + LR | `calendar_set` | Sai nhưng gần (cùng về quản lý thời gian) |\n",
    "| Word2Vec + Dense | `social_post` | Sai hoàn toàn |\n",
    "| LSTM (Pre-trained) | `general_dontcare` | Sai - mô hình bị collapse |\n",
    "| LSTM (Scratch) | `play_audiobook` | Sai - mô hình bị collapse |\n",
    "\n",
    "**Phân tích chi tiết:**\n",
    "- Câu này có **phụ thuộc xa quan trọng**: từ \"NOT\" ở giữa câu phủ định hành động \"call\"\n",
    "- **Ngữ cảnh phức tạp**: \"remind to NOT do X\" khác hoàn toàn với \"remind to do X\"\n",
    "- **Kỳ vọng:** LSTM với khả năng xử lý chuỗi nên hiểu được mối quan hệ này\n",
    "- **Thực tế:** LSTM thất bại hoàn toàn, không học được pattern nào\n",
    "- **TF-IDF tốt hơn:** Dù không hiểu phủ định, nhưng các từ \"remind\", \"me\" đủ mạnh để phân loại vào nhóm task management\n",
    "\n",
    "---\n",
    "\n",
    "### **Câu 2: \"is it going to be sunny OR rainy tomorrow\"**\n",
    "**Nhãn thực tế mong đợi:** `weather_query`\n",
    "\n",
    "| Mô hình | Dự đoán | Đánh giá |\n",
    "|---------|---------|----------|\n",
    "| TF-IDF + LR | `weather_query` |**ĐÚNG** |\n",
    "| Word2Vec + Dense | `weather_query` |**ĐÚNG** |\n",
    "| LSTM (Pre-trained) | `general_dontcare` |Sai - mô hình bị collapse |\n",
    "| LSTM (Scratch) | `play_audiobook` |Sai - mô hình bị collapse |\n",
    "\n",
    "**Phân tích chi tiết:**\n",
    "- Câu này có **từ khóa rõ ràng**: \"sunny\", \"rainy\", \"tomorrow\", \"weather\"\n",
    "- **Cấu trúc OR:** \"sunny OR rainy\" cần hiểu logic chọn lựa\n",
    "- **Kỳ vọng:** Cả bag-of-words và LSTM đều nên đoán đúng\n",
    "- **Thực tế:** Chỉ TF-IDF và Word2Vec thành công\n",
    "- **Nguyên nhân thành công của baseline:** Các từ domain-specific (\"sunny\", \"rainy\") là strong signals\n",
    "\n",
    "---\n",
    "\n",
    "### **Câu 3: \"find a flight from new york to london BUT NOT through paris\"**\n",
    "**Nhãn thực tế mong đợi:** `transport_query` hoặc `flight_search`\n",
    "\n",
    "| Mô hình | Dự đoán | Đánh giá |\n",
    "|---------|---------|----------|\n",
    "| TF-IDF + LR | `transport_query` | **ĐÚNG** hoặc gần đúng |\n",
    "| Word2Vec + Dense | `email_sendemail` | Sai hoàn toàn |\n",
    "| LSTM (Pre-trained) | `general_dontcare` | Sai - mô hình bị collapse |\n",
    "| LSTM (Scratch) | `play_audiobook` | Sai - mô hình bị collapse |\n",
    "\n",
    "**Phân tích chi tiết:**\n",
    "- Đây là **câu phức tạp nhất** với:\n",
    "  - Phụ thuộc xa: \"BUT NOT through paris\" phủ định điều kiện ở cuối\n",
    "  - Ngữ cảnh đa thành phần: origin, destination, constraint\n",
    "  - Yêu cầu hiểu logic điều kiện\n",
    "- **Kỳ vọng:** LSTM với khả năng xử lý chuỗi dài nên vượt trội\n",
    "- **Thực tế:** LSTM thất bại thảm hại\n",
    "- **TF-IDF thành công:** Từ \"flight\", \"new york\", \"london\" đủ mạnh để phân loại đúng\n",
    "- **Word2Vec sai nghiêm trọng:** Có thể do vector trung bình làm mất đi cấu trúc câu\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Phân Tích Nguyên Nhân LSTM Thất Bại\n",
    "\n",
    "### 3.1. Hiện Tượng \"Model Collapse\"\n",
    "\n",
    "Cả hai mô hình LSTM đều cho thấy dấu hiệu **model collapse**:\n",
    "- **Accuracy cực thấp** (~1.8%): Gần như random guessing (1/64 classes ≈ 1.56%)\n",
    "- **Dự đoán chỉ 1-2 lớp:** \"general_dontcare\" và \"play_audiobook\" xuất hiện liên tục\n",
    "- **Loss cực cao** (4.12): Mô hình không học được gì\n",
    "\n",
    "### 3.2. Nguyên Nhân Có Thể\n",
    "\n",
    "#### **A. Vấn đề về Dữ liệu**\n",
    "1. **Kích thước tập train quá nhỏ** \n",
    "   - LSTM cần nhiều dữ liệu hơn nhiều so với phương pháp truyền thống\n",
    "   - TF-IDF + LR có thể học tốt với ít dữ liệu hơn\n",
    "\n",
    "2. **Mất cân bằng lớp nghiêm trọng**\n",
    "   - Một số lớp có quá ít mẫu\n",
    "   - LSTM có thể học bias về các lớp dominant\n",
    "\n",
    "3. **Chất lượng tokenization**\n",
    "   - Có thể vocab_size=5000 quá nhỏ\n",
    "   - OOV (Out-of-Vocabulary) words không được xử lý tốt\n",
    "\n",
    "#### **B. Vấn đề về Kiến trúc & Huấn luyện**\n",
    "\n",
    "1. **Embedding Matrix không hiệu quả**\n",
    "   ```\n",
    "   Từ tìm thấy trong Word2Vec: X/Y (tỷ lệ thấp?)\n",
    "   ```\n",
    "   - Nhiều từ trong test set không có trong Word2Vec\n",
    "   - Embedding pre-trained không trainable → không thể adapt\n",
    "\n",
    "2. **Hyperparameters không phù hợp**\n",
    "   - LSTM 128 units có thể quá lớn cho dataset nhỏ\n",
    "   - Dropout 0.2 có thể chưa đủ\n",
    "   - Batch size 32 có thể không tối ưu\n",
    "   - Learning rate mặc định có thể không phù hợp\n",
    "\n",
    "3. **Vanishing Gradient vẫn xảy ra**\n",
    "   - Dù LSTM được thiết kế để giải quyết vấn đề này\n",
    "   - Với max_len=50, vẫn có thể gặp khó khăn với phụ thuộc xa\n",
    "\n",
    "4. **Khởi tạo trọng số không tốt**\n",
    "   - Embedding từ Word2Vec có thể không phù hợp với domain\n",
    "   - Khởi tạo ngẫu nhiên (scratch) càng tệ hơn với data ít\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
