{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0be85f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import Counter\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8f0bd1",
   "metadata": {},
   "source": [
    "# TASK 1: Tải và Tiền xử lý Dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3add31fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_conllu(file_path):\n",
    "    sentences = []\n",
    "    current_sentence = []\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            \n",
    "            # Bỏ qua các dòng comment hoặc dòng trống\n",
    "            if not line or line.startswith('#'):\n",
    "                if line == '' and current_sentence:\n",
    "                    sentences.append(current_sentence)\n",
    "                    current_sentence = []\n",
    "                continue\n",
    "            \n",
    "            # Parse dòng dữ liệu\n",
    "            fields = line.split('\\t')\n",
    "            if len(fields) >= 4 and fields[0].isdigit():\n",
    "                word = fields[1]  # Cột 2 (FORM)\n",
    "                upos_tag = fields[3]  # Cột 4 (UPOS)\n",
    "                current_sentence.append((word, upos_tag))\n",
    "        \n",
    "        # Thêm câu cuối cùng nếu có\n",
    "        if current_sentence:\n",
    "            sentences.append(current_sentence)\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "\n",
    "def build_vocabulary(sentences):\n",
    "    word_counter = Counter()\n",
    "    tag_counter = Counter()\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        for word, tag in sentence:\n",
    "            word_counter[word] += 1\n",
    "            tag_counter[tag] += 1\n",
    "    \n",
    "    # Tạo word_to_ix với token đặc biệt <UNK> và <PAD>\n",
    "    word_to_ix = {'<PAD>': 0, '<UNK>': 1}\n",
    "    for word in word_counter:\n",
    "        word_to_ix[word] = len(word_to_ix)\n",
    "    \n",
    "    # Tạo tag_to_ix với token <PAD>\n",
    "    tag_to_ix = {'<PAD>': 0}\n",
    "    for tag in tag_counter:\n",
    "        tag_to_ix[tag] = len(tag_to_ix)\n",
    "    \n",
    "    return word_to_ix, tag_to_ix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d725d5",
   "metadata": {},
   "source": [
    "# TASK 2: Tạo PyTorch Dataset và DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60a76093",
   "metadata": {},
   "outputs": [],
   "source": [
    "class POSDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, sentences, word_to_ix, tag_to_ix):\n",
    "        self.sentences = sentences\n",
    "        self.word_to_ix = word_to_ix\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.sentences[idx]\n",
    "        \n",
    "        # Chuyển từ và nhãn thành indices\n",
    "        word_indices = [self.word_to_ix.get(word, self.word_to_ix['<UNK>']) \n",
    "                        for word, _ in sentence]\n",
    "        tag_indices = [self.tag_to_ix[tag] for _, tag in sentence]\n",
    "        \n",
    "        return torch.tensor(word_indices, dtype=torch.long), \\\n",
    "               torch.tensor(tag_indices, dtype=torch.long)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    sentences, tags = zip(*batch)\n",
    "    \n",
    "    # Padding sequences\n",
    "    sentences_padded = pad_sequence(sentences, batch_first=True, padding_value=0)\n",
    "    tags_padded = pad_sequence(tags, batch_first=True, padding_value=0)\n",
    "    \n",
    "    return sentences_padded, tags_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d772ace3",
   "metadata": {},
   "source": [
    "# TASK 3: Xây dựng Mô hình RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e025fad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNNForTokenClassification(nn.Module):\n",
    "    \"\"\"Mô hình RNN đơn giản cho bài toán POS Tagging.\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, tagset_size, embedding_dim, hidden_dim):\n",
    "        super(SimpleRNNForTokenClassification, self).__init__()\n",
    "        \n",
    "        # Lớp Embedding\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        # Lớp RNN\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "        \n",
    "        # Lớp Linear để dự đoán nhãn\n",
    "        self.fc = nn.Linear(hidden_dim, tagset_size)\n",
    "    \n",
    "    def forward(self, sentences):\n",
    "        # sentences: (batch_size, seq_len)\n",
    "        \n",
    "        # Embedding: (batch_size, seq_len, embedding_dim)\n",
    "        embeds = self.embedding(sentences)\n",
    "        \n",
    "        # RNN: rnn_out shape: (batch_size, seq_len, hidden_dim)\n",
    "        rnn_out, _ = self.rnn(embeds)\n",
    "        \n",
    "        # Linear: (batch_size, seq_len, tagset_size)\n",
    "        tag_space = self.fc(rnn_out)\n",
    "        \n",
    "        return tag_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c7f5c0",
   "metadata": {},
   "source": [
    "# TASK 4: Huấn luyện Mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54c7d8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer, criterion, device):\n",
    "    \"\"\"Huấn luyện mô hình trên một epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for sentences, tags in train_loader:\n",
    "        sentences, tags = sentences.to(device), tags.to(device)\n",
    "        \n",
    "        # 1. Xóa gradient cũ\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 2. Forward pass\n",
    "        outputs = model(sentences)\n",
    "        \n",
    "        # 3. Tính loss\n",
    "        # Reshape outputs và tags để tính loss\n",
    "        outputs = outputs.view(-1, outputs.shape[-1])  # (batch_size * seq_len, tagset_size)\n",
    "        tags = tags.view(-1)  # (batch_size * seq_len)\n",
    "        \n",
    "        loss = criterion(outputs, tags)\n",
    "        \n",
    "        # 4. Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. Cập nhật trọng số\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721235ab",
   "metadata": {},
   "source": [
    "# TASK 5: Đánh giá Mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dd0e82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device):\n",
    "    \"\"\"Đánh giá mô hình trên tập dữ liệu.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sentences, tags in data_loader:\n",
    "            sentences, tags = sentences.to(device), tags.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(sentences)\n",
    "            \n",
    "            # Lấy dự đoán\n",
    "            predictions = torch.argmax(outputs, dim=-1)\n",
    "            \n",
    "            # Tính accuracy (chỉ tính trên token không phải padding)\n",
    "            mask = tags != 0  # Mask cho padding\n",
    "            correct += ((predictions == tags) & mask).sum().item()\n",
    "            total += mask.sum().item()\n",
    "    \n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def predict_sentence(model, sentence, word_to_ix, ix_to_tag, device):\n",
    "    \"\"\"\n",
    "    Dự đoán POS tags cho một câu mới.\n",
    "    sentence: chuỗi văn bản, ví dụ: \"I love NLP\"\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Tách câu thành các từ\n",
    "    words = sentence.split()\n",
    "    \n",
    "    # Chuyển từ thành indices\n",
    "    word_indices = [word_to_ix.get(word, word_to_ix['<UNK>']) for word in words]\n",
    "    sentence_tensor = torch.tensor([word_indices], dtype=torch.long).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(sentence_tensor)\n",
    "        predictions = torch.argmax(outputs, dim=-1)\n",
    "    \n",
    "    # Chuyển predictions thành tags\n",
    "    predicted_tags = [ix_to_tag[idx.item()] for idx in predictions[0]]\n",
    "    \n",
    "    return list(zip(words, predicted_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01bdc69",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fee5d011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "=== TASK 1: Loading and Preprocessing Data ===\n",
      "Number of training sentences: 12544\n",
      "Number of dev sentences: 2001\n",
      "Example sentence: [('Al', 'PROPN'), ('-', 'PUNCT'), ('Zaman', 'PROPN'), (':', 'PUNCT'), ('American', 'ADJ')]\n",
      "\n",
      "Vocabulary size: 19675\n",
      "Tagset size: 18\n",
      "Tags: ['<PAD>', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'DET', 'ADP', 'AUX', 'PRON', 'PART', 'SCONJ', 'NUM', 'ADV', 'CCONJ', 'X', 'INTJ', 'SYM']\n",
      "\n",
      "=== TASK 2: Creating Dataset and DataLoader ===\n",
      "Number of training batches: 392\n",
      "Number of dev batches: 63\n",
      "\n",
      "=== TASK 3: Building RNN Model ===\n",
      "Model architecture:\n",
      "SimpleRNNForTokenClassification(\n",
      "  (embedding): Embedding(19675, 100, padding_idx=0)\n",
      "  (rnn): RNN(100, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=18, bias=True)\n",
      ")\n",
      "\n",
      "=== TASK 4 & 5: Training and Evaluation ===\n",
      "Epoch 1/10\n",
      "  Train Loss: 1.1228 | Train Acc: 0.7700\n",
      "  Dev Acc: 0.7477\n",
      "  -> New best model saved!\n",
      "Epoch 2/10\n",
      "  Train Loss: 0.6224 | Train Acc: 0.8384\n",
      "  Dev Acc: 0.8033\n",
      "  -> New best model saved!\n",
      "Epoch 3/10\n",
      "  Train Loss: 0.4689 | Train Acc: 0.8766\n",
      "  Dev Acc: 0.8300\n",
      "  -> New best model saved!\n",
      "Epoch 4/10\n",
      "  Train Loss: 0.3741 | Train Acc: 0.9007\n",
      "  Dev Acc: 0.8460\n",
      "  -> New best model saved!\n",
      "Epoch 5/10\n",
      "  Train Loss: 0.3058 | Train Acc: 0.9208\n",
      "  Dev Acc: 0.8548\n",
      "  -> New best model saved!\n",
      "Epoch 6/10\n",
      "  Train Loss: 0.2532 | Train Acc: 0.9327\n",
      "  Dev Acc: 0.8629\n",
      "  -> New best model saved!\n",
      "Epoch 7/10\n",
      "  Train Loss: 0.2123 | Train Acc: 0.9463\n",
      "  Dev Acc: 0.8669\n",
      "  -> New best model saved!\n",
      "Epoch 8/10\n",
      "  Train Loss: 0.1788 | Train Acc: 0.9529\n",
      "  Dev Acc: 0.8697\n",
      "  -> New best model saved!\n",
      "Epoch 9/10\n",
      "  Train Loss: 0.1507 | Train Acc: 0.9616\n",
      "  Dev Acc: 0.8726\n",
      "  -> New best model saved!\n",
      "Epoch 10/10\n",
      "  Train Loss: 0.1275 | Train Acc: 0.9684\n",
      "  Dev Acc: 0.8744\n",
      "  -> New best model saved!\n",
      "\n",
      "=== Final Results ===\n",
      "Best Dev Accuracy: 0.8744\n",
      "\n",
      "=== Predicting New Sentences ===\n",
      "\n",
      "Sentence: 'I love NLP'\n",
      "Predictions: [('I', 'PRON'), ('love', 'VERB'), ('NLP', 'NOUN')]\n",
      "\n",
      "Sentence: 'The cat sits on the mat'\n",
      "Predictions: [('The', 'DET'), ('cat', 'NOUN'), ('sits', 'NOUN'), ('on', 'ADP'), ('the', 'DET'), ('mat', 'NOUN')]\n",
      "\n",
      "Sentence: 'She is reading a book'\n",
      "Predictions: [('She', 'PRON'), ('is', 'AUX'), ('reading', 'VERB'), ('a', 'DET'), ('book', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Thiết lập device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Đường dẫn đến dữ liệu\n",
    "    data_dir = r'D:\\10. ky1nam4\\NLP\\data\\UD_English-EWT'\n",
    "    train_file = os.path.join(data_dir, 'en_ewt-ud-train.conllu')\n",
    "    dev_file = os.path.join(data_dir, 'en_ewt-ud-dev.conllu')\n",
    "    \n",
    "    # Task 1: Load dữ liệu\n",
    "    print(\"\\n=== TASK 1: Loading and Preprocessing Data ===\")\n",
    "    train_sentences = load_conllu(train_file)\n",
    "    dev_sentences = load_conllu(dev_file)\n",
    "    \n",
    "    print(f\"Number of training sentences: {len(train_sentences)}\")\n",
    "    print(f\"Number of dev sentences: {len(dev_sentences)}\")\n",
    "    print(f\"Example sentence: {train_sentences[0][:5]}\")\n",
    "    \n",
    "    # Xây dựng vocabulary\n",
    "    word_to_ix, tag_to_ix = build_vocabulary(train_sentences)\n",
    "    ix_to_tag = {v: k for k, v in tag_to_ix.items()}\n",
    "    \n",
    "    print(f\"\\nVocabulary size: {len(word_to_ix)}\")\n",
    "    print(f\"Tagset size: {len(tag_to_ix)}\")\n",
    "    print(f\"Tags: {list(tag_to_ix.keys())}\")\n",
    "    \n",
    "    # Task 2: Tạo Dataset và DataLoader\n",
    "    print(\"\\n=== TASK 2: Creating Dataset and DataLoader ===\")\n",
    "    train_dataset = POSDataset(train_sentences, word_to_ix, tag_to_ix)\n",
    "    dev_dataset = POSDataset(dev_sentences, word_to_ix, tag_to_ix)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "    dev_loader = DataLoader(dev_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "    \n",
    "    print(f\"Number of training batches: {len(train_loader)}\")\n",
    "    print(f\"Number of dev batches: {len(dev_loader)}\")\n",
    "    \n",
    "    # Task 3: Xây dựng mô hình\n",
    "    print(\"\\n=== TASK 3: Building RNN Model ===\")\n",
    "    EMBEDDING_DIM = 100\n",
    "    HIDDEN_DIM = 128\n",
    "    \n",
    "    model = SimpleRNNForTokenClassification(\n",
    "        vocab_size=len(word_to_ix),\n",
    "        tagset_size=len(tag_to_ix),\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        hidden_dim=HIDDEN_DIM\n",
    "    ).to(device)\n",
    "    \n",
    "    print(f\"Model architecture:\\n{model}\")\n",
    "    \n",
    "    # Task 4 & 5: Huấn luyện và đánh giá\n",
    "    print(\"\\n=== TASK 4 & 5: Training and Evaluation ===\")\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding\n",
    "    \n",
    "    NUM_EPOCHS = 10\n",
    "    best_dev_acc = 0\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # Huấn luyện\n",
    "        train_loss = train_model(model, train_loader, optimizer, criterion, device)\n",
    "        \n",
    "        # Đánh giá\n",
    "        train_acc = evaluate(model, train_loader, device)\n",
    "        dev_acc = evaluate(model, dev_loader, device)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"  Dev Acc: {dev_acc:.4f}\")\n",
    "        \n",
    "        # Lưu mô hình tốt nhất\n",
    "        if dev_acc > best_dev_acc:\n",
    "            best_dev_acc = dev_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "            print(f\"  -> New best model saved!\")\n",
    "    \n",
    "    # Load mô hình tốt nhất và đánh giá\n",
    "    print(\"\\n=== Final Results ===\")\n",
    "    model.load_state_dict(torch.load('best_model.pt'))\n",
    "    final_dev_acc = evaluate(model, dev_loader, device)\n",
    "    print(f\"Best Dev Accuracy: {final_dev_acc:.4f}\")\n",
    "    \n",
    "    # Test dự đoán câu mới\n",
    "    print(\"\\n=== Predicting New Sentences ===\")\n",
    "    test_sentences = [\n",
    "        \"I love NLP\",\n",
    "        \"The cat sits on the mat\",\n",
    "        \"She is reading a book\"\n",
    "    ]\n",
    "    \n",
    "    for sentence in test_sentences:\n",
    "        predictions = predict_sentence(model, sentence, word_to_ix, ix_to_tag, device)\n",
    "        print(f\"\\nSentence: '{sentence}'\")\n",
    "        print(f\"Predictions: {predictions}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0772ab9",
   "metadata": {},
   "source": [
    "# BÁO CÁO LAB 5: Xây dựng mô hình RNN cho bài toán POS Tagging\n",
    "\n",
    "## 1. Mục tiêu\n",
    "Trong bài thực hành này, chúng ta áp dụng kiến thức về mạng nơ-ron hồi quy (RNN) để xây dựng mô hình dự đoán nhãn Part-of-Speech (POS) cho từng token trong câu. Các bước chính:\n",
    "- Tiền xử lý dữ liệu từ định dạng CoNLL-U.\n",
    "- Xây dựng từ điển cho từ và nhãn.\n",
    "- Tạo Dataset và DataLoader trong PyTorch.\n",
    "- Xây dựng mô hình RNN đơn giản với các lớp `Embedding`, `RNN`, và `Linear`.\n",
    "- Huấn luyện và đánh giá mô hình.\n",
    "\n",
    "## 2. Bộ dữ liệu\n",
    "- Sử dụng bộ dữ liệu **UD_English-EWT** ở định dạng CoNLL-U.\n",
    "- Số lượng câu:\n",
    "  - Train: **12,544 câu**\n",
    "  - Dev: **2,001 câu**\n",
    "- Ví dụ một câu sau khi xử lý: [('Al', 'PROPN'), ('-', 'PUNCT'), ('Zaman', 'PROPN'), (':', 'PUNCT'), ('American', 'ADJ')]\n",
    "- Kích thước từ điển:\n",
    "- Vocabulary: **19,675 từ**\n",
    "- Tagset: **18 nhãn**\n",
    "- Các nhãn: `<PAD>`, PROPN, PUNCT, ADJ, NOUN, VERB, DET, ADP, AUX, PRON, PART, SCONJ, NUM, ADV, CCONJ, X, INTJ, SYM.\n",
    "\n",
    "## 3. Mô hình\n",
    "- Kiến trúc: SimpleRNNForTokenClassification(\n",
    "(embedding): Embedding(19675, 100, padding_idx=0)\n",
    "(rnn): RNN(100, 128, batch_first=True)\n",
    "(fc): Linear(in_features=128, out_features=18, bias=True)\n",
    ")\n",
    "\n",
    "## 4. Huấn luyện\n",
    "- Số epoch: **10**\n",
    "- Optimizer: Adam\n",
    "- Loss: CrossEntropyLoss (ignore_index cho padding)\n",
    "- Kết quả huấn luyện:\n",
    "\n",
    "| Epoch | Train Loss | Train Acc | Dev Acc |\n",
    "|-------|-----------|-----------|---------|\n",
    "| 1     | 1.1228    | 0.7700    | 0.7477 |\n",
    "| 5     | 0.3058    | 0.9208    | 0.8548 |\n",
    "| 10    | 0.1275    | 0.9684    | 0.8744 |\n",
    "\n",
    "- **Best Dev Accuracy:** **0.8744**\n",
    "\n",
    "## 5. Dự đoán câu mới\n",
    "- **Câu:** \"I love NLP\"  \n",
    "**Dự đoán:** `[('I', 'PRON'), ('love', 'VERB'), ('NLP', 'NOUN')]`\n",
    "\n",
    "- **Câu:** \"The cat sits on the mat\"  \n",
    "**Dự đoán:** `[('The', 'DET'), ('cat', 'NOUN'), ('sits', 'NOUN'), ('on', 'ADP'), ('the', 'DET'), ('mat', 'NOUN')]`\n",
    "\n",
    "- **Câu:** \"She is reading a book\"  \n",
    "**Dự đoán:** `[('She', 'PRON'), ('is', 'AUX'), ('reading', 'VERB'), ('a', 'DET'), ('book', 'NOUN')]`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
