{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed71dc3f",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1623a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "\n",
    "PAD_TOKEN = \"<PAD>\"\n",
    "UNK_TOKEN = \"<UNK>\"\n",
    "PAD_TAG_IDX = -100 \n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22fc3e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Task 1: Tải và Tiền xử lý Dữ liệu ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\10. ky1nam4\\NLP\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in E:\\hf_cache\\hub\\datasets--lhoestq--conll2003. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Generating train split: 100%|██████████| 14041/14041 [00:00<00:00, 215107.05 examples/s]\n",
      "Generating validation split: 100%|██████████| 3250/3250 [00:00<00:00, 464177.07 examples/s]\n",
      "Generating test split: 100%|██████████| 3453/3453 [00:00<00:00, 690781.82 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bộ dữ liệu đã tải: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 14041\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 3250\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 3453\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Task 1: Tải và Tiền xử lý Dữ liệu ---\")\n",
    "\n",
    "dataset = load_dataset(\"lhoestq/conll2003\")\n",
    "print(f\"Bộ dữ liệu đã tải: {dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c469f613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Danh sách tên nhãn NER: ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n"
     ]
    }
   ],
   "source": [
    "train_sentences = dataset[\"train\"][\"tokens\"]\n",
    "train_tags_numerical = dataset[\"train\"][\"ner_tags\"] \n",
    "val_sentences = dataset[\"validation\"][\"tokens\"]\n",
    "val_tags_numerical = dataset[\"validation\"][\"ner_tags\"]\n",
    "test_sentences = dataset[\"test\"][\"tokens\"] \n",
    "test_tags_numerical = dataset[\"test\"][\"ner_tags\"]\n",
    "\n",
    "tag_names = ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
    "print(f\"Danh sách tên nhãn NER: {tag_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa296681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_numerical_tags_to_strings(tags_numerical):\n",
    "    tags_string = []\n",
    "    for sent_tags in tags_numerical:\n",
    "        tags_string.append([tag_names[tag_idx] for tag_idx in sent_tags])\n",
    "    return tags_string\n",
    "\n",
    "train_tags = convert_numerical_tags_to_strings(train_tags_numerical)\n",
    "val_tags = convert_numerical_tags_to_strings(val_tags_numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a53e242b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kích thước Từ điển Từ (VOCAB_SIZE): 23625\n",
      "Kích thước Từ điển Nhãn (OUTPUT_SIZE): 9\n"
     ]
    }
   ],
   "source": [
    "word_counts = Counter(word for sentence in train_sentences for word in sentence)\n",
    "words = list(word_counts.keys())\n",
    "\n",
    "word_to_ix = {PAD_TOKEN: 0, UNK_TOKEN: 1}\n",
    "for word in words:\n",
    "    if word not in word_to_ix:\n",
    "        word_to_ix[word] = len(word_to_ix)\n",
    "        \n",
    "tag_to_ix = {}\n",
    "for tag in tag_names:\n",
    "    if tag not in tag_to_ix:\n",
    "        tag_to_ix[tag] = len(tag_to_ix)\n",
    "        \n",
    "VOCAB_SIZE = len(word_to_ix)\n",
    "OUTPUT_SIZE = len(tag_to_ix)\n",
    "print(f\"\\nKích thước Từ điển Từ (VOCAB_SIZE): {VOCAB_SIZE}\")\n",
    "print(f\"Kích thước Từ điển Nhãn (OUTPUT_SIZE): {OUTPUT_SIZE}\")\n",
    "\n",
    "PAD_WORD_IDX = word_to_ix[PAD_TOKEN]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e90c827",
   "metadata": {},
   "source": [
    "# Task 2: Tạo PyTorch Dataset và DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bf47e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(self, sentences, tags, word_to_ix, tag_to_ix):\n",
    "        self.sentences = sentences\n",
    "        self.tags = tags\n",
    "        self.word_to_ix = word_to_ix\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.unk_idx = word_to_ix[UNK_TOKEN]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.sentences[idx]\n",
    "        tags = self.tags[idx]\n",
    "        sentence_indices = [self.word_to_ix.get(word, self.unk_idx) for word in sentence]\n",
    "        tag_indices = [self.tag_to_ix[tag] for tag in tags]\n",
    "        \n",
    "        return torch.tensor(sentence_indices, dtype=torch.long), torch.tensor(tag_indices, dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    sentences = [item[0] for item in batch]\n",
    "    tags = [item[1] for item in batch]\n",
    "    \n",
    "    sentences_padded = nn.utils.rnn.pad_sequence(\n",
    "        sentences, \n",
    "        batch_first=True, \n",
    "        padding_value=PAD_WORD_IDX\n",
    "    )\n",
    "    tags_padded = nn.utils.rnn.pad_sequence(\n",
    "        tags, \n",
    "        batch_first=True, \n",
    "        padding_value=PAD_TAG_IDX\n",
    "    )\n",
    "    \n",
    "    return sentences_padded, tags_padded\n",
    "\n",
    "train_dataset = NERDataset(train_sentences, train_tags, word_to_ix, tag_to_ix)\n",
    "val_dataset = NERDataset(val_sentences, val_tags, word_to_ix, tag_to_ix)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5a046c",
   "metadata": {},
   "source": [
    "# Task 3: Xây dựng Mô hình RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96479ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNNForTokenClassification(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_size, rnn_type='GRU'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=PAD_WORD_IDX)\n",
    "        if rnn_type == 'LSTM':\n",
    "            self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        elif rnn_type == 'GRU':\n",
    "            self.rnn = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        else:\n",
    "            self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        embedded = self.embedding(sentences)\n",
    "        output, _ = self.rnn(embedded)\n",
    "        output_linear = self.linear(output)\n",
    "        return output_linear\n",
    "\n",
    "model = SimpleRNNForTokenClassification(\n",
    "    vocab_size=VOCAB_SIZE, \n",
    "    embedding_dim=EMBEDDING_DIM, \n",
    "    hidden_dim=HIDDEN_DIM, \n",
    "    output_size=OUTPUT_SIZE,\n",
    "    rnn_type='GRU' \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f547f3c",
   "metadata": {},
   "source": [
    "# Task 4: Huấn luyện Mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efc56ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.6537\n",
      "Epoch 2/5, Loss: 0.3485\n",
      "Epoch 3/5, Loss: 0.2215\n",
      "Epoch 4/5, Loss: 0.1474\n",
      "Epoch 5/5, Loss: 0.0983\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=PAD_TAG_IDX) \n",
    "model.train() \n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_loss = 0\n",
    "    for sentences_batch, tags_batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(sentences_batch)\n",
    "        loss = loss_function(\n",
    "            predictions.view(-1, OUTPUT_SIZE), \n",
    "            tags_batch.view(-1)\n",
    "        )\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb482357",
   "metadata": {},
   "source": [
    "# Task 5: Đánh giá Mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0254cae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ chính xác trên tập validation: 93.14%\n",
      "\n",
      "Câu: \"VNU University is located in Hanoi\"\n",
      "Dự đoán:\n",
      "(VNU, B-ORG)\n",
      "(University, I-ORG)\n",
      "(is, O)\n",
      "(located, O)\n",
      "(in, O)\n",
      "(Hanoi, B-LOC)\n",
      "\n",
      "KẾT QUẢ THỰC HIỆN\n",
      "• Độ chính xác trên tập validation: 93.14%\n",
      "• Ví dụ dự đoán câu mới: Xem kết quả in ra cho câu \"VNU University is located in Hanoi\"\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_tokens = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sentences_batch, tags_batch in dataloader:\n",
    "            \n",
    "            predictions_raw = model(sentences_batch)\n",
    "            predictions_index = torch.argmax(predictions_raw, dim=-1)\n",
    "            mask = (tags_batch != PAD_TAG_IDX)\n",
    "            correct_predictions = (predictions_index == tags_batch) & mask\n",
    "            \n",
    "            total_correct += correct_predictions.sum().item()\n",
    "            total_tokens += mask.sum().item()\n",
    "            \n",
    "    accuracy = total_correct / total_tokens if total_tokens > 0 else 0\n",
    "    model.train()\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "val_accuracy = evaluate(model, val_dataloader)\n",
    "print(f\"Độ chính xác trên tập validation: {val_accuracy*100:.2f}%\")\n",
    "\n",
    "ix_to_tag = {v: k for k, v in tag_to_ix.items()}\n",
    "\n",
    "def predict_sentence(sentence_str, model, word_to_ix, ix_to_tag):\n",
    "    print(f\"\\nCâu: \\\"{sentence_str}\\\"\")\n",
    "    tokens = sentence_str.split()\n",
    "    \n",
    "    unk_idx = word_to_ix[UNK_TOKEN]\n",
    "    token_indices = [word_to_ix.get(token, unk_idx) for token in tokens]\n",
    "    \n",
    "    input_tensor = torch.tensor(token_indices, dtype=torch.long).unsqueeze(0)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions_raw = model(input_tensor)\n",
    "        predictions_index = torch.argmax(predictions_raw, dim=-1).squeeze(0).tolist()\n",
    "        \n",
    "    model.train()\n",
    "    predicted_tags = [ix_to_tag[idx] for idx in predictions_index]\n",
    "    \n",
    "    print(\"Dự đoán:\")\n",
    "    for word, tag in zip(tokens, predicted_tags):\n",
    "        print(f\"({word}, {tag})\")\n",
    "\n",
    "test_sentence = \"VNU University is located in Hanoi\"\n",
    "predict_sentence(test_sentence, model, word_to_ix, ix_to_tag)\n",
    "\n",
    "print(\"\\nKẾT QUẢ THỰC HIỆN\")\n",
    "print(f\"• Độ chính xác trên tập validation: {val_accuracy*100:.2f}%\")\n",
    "print(f\"• Ví dụ dự đoán câu mới: Xem kết quả in ra cho câu \\\"{test_sentence}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1f5663",
   "metadata": {},
   "source": [
    "# Báo Cáo Lab 5: Xây dựng Mô hình RNN cho Bài toán Nhận dạng Thực thể Tên (NER)\n",
    "\n",
    "* **Mục tiêu:** Xây dựng mô hình Mạng Nơ-ron Hồi quy (GRU) để phân loại thực thể tên trên từng token, sử dụng bộ dữ liệu CoNLL 2003.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Quá trình Thực hiện (Tasks 1-5)\n",
    "\n",
    "### Task 1: Tải và Tiền xử lý Dữ liệu\n",
    "\n",
    "1.  [cite_start]**Tải Dữ liệu:** Sử dụng thư viện `datasets` để tải bộ dữ liệu **CoNLL 2003**[cite: 13, 14].\n",
    "    * **Khắc phục Lỗi API:** Do lỗi `AttributeError` khi truy cập thuộc tính `.names` của metadata, danh sách tên nhãn NER đã được **định nghĩa thủ công** theo chuẩn IOB2 của CoNLL 2003:\n",
    "        ```python\n",
    "        tag_names = ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
    "        ```\n",
    "2.  **Xây dựng Từ điển (Vocabulary):**\n",
    "    * **Kích thước Từ điển Từ (VOCAB_SIZE):** 23625\n",
    "    * **Kích thước Từ điển Nhãn (OUTPUT_SIZE):** 9\n",
    "\n",
    "---\n",
    "\n",
    "### Task 2: Tạo PyTorch Dataset và DataLoader\n",
    "\n",
    "1.  [cite_start]**Lớp `NERDataset`:** Xử lý việc ánh xạ từ và nhãn sang các chỉ số số nguyên (`token_indices`, `tag_indices`)[cite: 44, 47, 48].\n",
    "2.  [cite_start]**Hàm `collate_fn`:** Thực hiện đệm (padding) động cho các câu và nhãn trong mỗi batch bằng `torch.nn.utils.rnn.pad_sequence`[cite: 52].\n",
    "    * [cite_start]**Padding cho nhãn:** Sử dụng chỉ số đặc biệt **`PAD_TAG_IDX = -100`** để các token đệm bị bỏ qua trong tính toán hàm lỗi[cite: 53].\n",
    "\n",
    "---\n",
    "\n",
    "### Task 3: Xây dựng Mô hình RNN\n",
    "\n",
    "[cite_start]Mô hình **`SimpleRNNForTokenClassification`** được xây dựng với kiến trúc 3 lớp[cite: 56]:\n",
    "1.  **`nn.Embedding`**: Lớp embedding từ.\n",
    "2.  [cite_start]**`nn.GRU`**: Sử dụng GRU (thay cho RNN cơ bản) để xử lý chuỗi và trích xuất ngữ cảnh[cite: 58].\n",
    "3.  **`nn.Linear`**: Ánh xạ output của RNN sang không gian nhãn.\n",
    "\n",
    "---\n",
    "\n",
    "### Task 4: Huấn luyện Mô hình\n",
    "\n",
    "1.  [cite_start]**Loss Function:** `nn.CrossEntropyLoss` được sử dụng[cite: 65, 66].\n",
    "2.  [cite_start]**Thiết lập `ignore_index`:** Tham số **`ignore_index`** được đặt bằng **`-100`** để đảm bảo hàm lỗi bỏ qua các vị trí padding khi tính toán[cite: 67, 68].\n",
    "3.  [cite_start]**Optimizer:** `torch.optim.Adam` được sử dụng[cite: 65].\n",
    "4.  Mô hình được huấn luyện trong **5 epochs**.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Kết quả Đánh giá (Task 5)\n",
    "\n",
    "### Đánh giá Độ chính xác trên Tập Validation\n",
    "\n",
    "[cite_start]Độ chính xác được tính trên các token **không phải padding** của tập validation[cite: 81, 82].\n",
    "\n",
    "| Chỉ số | Giá trị |\n",
    "| :--- | :--- |\n",
    "| **Độ chính xác trên tập validation (Accuracy)** | **93.14%** |\n",
    "\n",
    "### Ví dụ Dự đoán Câu mới\n",
    "\n",
    "[cite_start]Đã chạy hàm `predict_sentence` với câu thử nghiệm mới để kiểm tra khả năng khái quát hóa của mô hình[cite: 87]:\n",
    "\n",
    "| Câu gốc: | \"VNU University is located in Hanoi\" |\n",
    "| :--- | :--- |\n",
    "| VNU | B-ORG |\n",
    "| University | I-ORG |\n",
    "| is | O |\n",
    "| located | O |\n",
    "| in | O |\n",
    "| Hanoi | B-LOC |\n",
    "\n",
    "**Nhận xét:** Mô hình đã nhận diện chính xác \"VNU University\" là một thực thể Tổ chức (ORG) và \"Hanoi\" là một thực thể Địa điểm (LOC).\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Nộp bài\n",
    "\n",
    "**KẾT QUẢ THỰC HIỆN**\n",
    "\n",
    "* **Độ chính xác trên tập validation:** **93.14%**\n",
    "* **Ví dụ dự đoán câu mới:** Xem kết quả in ra cho câu \"VNU University is located in Hanoi\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
